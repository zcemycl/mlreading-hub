{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hidden Markov Models (HMMs)\n",
    "$$\\begin{align*}P(O) &= \\sum_Q P(O,Q)=\\sum_Q P(O|Q)P(Q) \\\\ &= \\sum_{j=1}^N \\prod^T_{i=1}P(o_i|q_i)P(q_i|q_{i-1})= \\sum_{j=1}^N \\prod^T_{i=1}a_{ij}b(o_i)\n",
    "\\end{align*}$$\n",
    "It is useful for 3 fundamental problems, \n",
    "1. Likelihood \n",
    "<p> Given an HMM $\\lambda = (A,B)$ and an observation sequence $O$, determine the likelihood $P(O|\\lambda)$. </p>\n",
    "2. Decoding\n",
    "<p> Given an observation sequence $O$ and and HMM $\\lambda=(A,B)$, discover the best hidden state sequence Q. </p>\n",
    "3. Learning\n",
    "<p> Given an observation sequence $O$ and the set of states in the HMM, learn the HMM parameters $A$ and $B$. </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HMM:\n",
    "    def __init__(self):\n",
    "        self.params = defaultdict(dict)\n",
    "        self.o2id,self.id2o = dict(),dict()\n",
    "        self.q2id,self.id2q = dict(),dict()\n",
    "    def _setDistinctObservations(self,distO):\n",
    "        self.o = len(distO)\n",
    "        for i,o in enumerate(distO):\n",
    "            self.o2id[o]=i\n",
    "            self.id2o[i]=o\n",
    "    def _setDistinctHiddens(self,distQ):\n",
    "        self.q = len(distQ)\n",
    "        A = np.random.uniform(0,1,(self.q,self.q))\n",
    "        A /= np.sum(A,axis=1,keepdims=1)\n",
    "        B = np.random.uniform(0,1,(self.q,self.o))\n",
    "        B /= np.sum(B,axis=1,keepdims=1)\n",
    "        pi = np.random.uniform(0,1,self.q)\n",
    "        pi/= np.sum(pi)\n",
    "        self.A = defaultdict(dict)\n",
    "        self.B = defaultdict(dict)\n",
    "        self.pi = {}\n",
    "        for i,q in enumerate(distQ):\n",
    "            self.q2id[q]=i\n",
    "            self.id2q[i]=q\n",
    "            for j,q_ in enumerate(distQ):\n",
    "                self.A[i][j] = A[i][j]\n",
    "            for k in range(self.o):\n",
    "                self.B[i][k] = B[i][k]\n",
    "            self.pi[i] = pi[i]\n",
    "    def setDistinctHiddensAndObservations(self,distO,distQ):\n",
    "        self._setDistinctObservations(distO)\n",
    "        self._setDistinctHiddens(distQ)\n",
    "    def setSpecificEmit(self,qSym,emitDict):\n",
    "        assert sum(emitDict.values())==1, \"Sum of probability is not 1\"\n",
    "        for i in self.B[self.q2id[qSym]].keys():\n",
    "            # assert in dict\n",
    "            self.B[self.q2id[qSym]][i]=emitDict.get(self.id2o[i],0)\n",
    "        assert sum(self.B[self.q2id[qSym]].values())==1, \"Sum of probability is not 1\"\n",
    "    def setSpecificTransit(self,qSym,tranDict):\n",
    "        assert sum(tranDict.values())==1, \"Sum of probability is not 1\"\n",
    "        for i in self.A[self.q2id[qSym]].keys():\n",
    "            self.A[self.q2id[qSym]][i]=tranDict.get(self.id2q[i],0)\n",
    "        assert sum(self.A[self.q2id[qSym]].values())==1, \"Sum of probability is not 1\"\n",
    "    def setInitial(self,initDict):\n",
    "        assert sum(initDict.values())==1, \"Sum of probability is not 1\"\n",
    "        for i in self.pi.keys():\n",
    "            # assert in dict\n",
    "            self.pi[i]=initDict.get(self.id2q[i],0)\n",
    "        assert sum(self.pi.values())==1, \"Sum of probability is not 1\"\n",
    "    def computeLikelihood(self,Os):\n",
    "        raise NotImplementedError(\"You need to implement function1 when you inherit from Model\")\n",
    "    def decode(self,Os):\n",
    "        raise NotImplementedError(\"You need to implement function1 when you inherit from Model\")\n",
    "    def learn(self,Qs,Os):\n",
    "        raise NotImplementedError(\"You need to implement function1 when you inherit from Model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "hmm = HMM()\n",
    "hmm.setDistinctHiddensAndObservations([0,1,2,3],[\"H\",\"C\"])\n",
    "hmm.setInitial({\"H\":0.7,\"C\":0.3})\n",
    "hmm.setSpecificTransit(\"H\",{\"H\":0.7,\"C\":0.3})\n",
    "hmm.setSpecificTransit(\"C\",{\"H\":0.8,\"C\":0.2})\n",
    "hmm.setSpecificEmit(\"H\",{0:0.2,1:0.7,2:0.05,3:0.05})\n",
    "hmm.setSpecificEmit(\"C\",{0:0.9,1:0.05,2:0.05})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Likelihood: Forward Algorithm\n",
    "a. Initialization\n",
    "$$\\alpha_1(j) = \\pi_jb_j(o_1) \\qquad 1\\leq j\\leq N$$\n",
    "b. Recursion\n",
    "$$\\begin{align*}\\alpha_t(j) &= P(\\{o_i\\}_{i=1}^t, q_t=j|\\lambda) \\\\ \n",
    "&= \\sum^N_{i=1}\\alpha_{t-1}(i)a_{ij}b_j(o_t) \\qquad 1\\leq j\\leq N\\quad ,\\quad 1<t\\leq T \\end{align*}$$\n",
    "c. Termination\n",
    "$$\n",
    "P(O|\\lambda) = \\sum^N_{i=1}\\alpha_T(i)\n",
    "$$\n",
    "<details>\n",
    "<summary><h4>Click to view proof for Forward probability!</h4></summary>\n",
    "$$\\begin{align*}\n",
    "\\alpha_t(j) &= P(\\{o_k\\}^t_1,q_t=j|\\lambda) = \\sum^N_{i=1} P(\\{o_k\\}^{t-1}_1,o_t,q_t=j,q_{t-1}=i|\\lambda)\\\\\n",
    "&= \\sum^N_{i=1}P(o_t|\\{o_k\\}^{t-1}_1,q_t=j,q_{t-1}=i,\\lambda)P(q_t=j|\\{o_k\\}^{t-1}_1,q_{t-1}=i,\\lambda) \\\\ &\\qquad \\times P(\\{o_k\\}^{t-1}_1,q_{t-1}=i|\\lambda) \\\\\n",
    "&= \\sum^N_{i=1}P(\\{o_k\\}^{t-1}_1,q_{t-1}=i|\\lambda)P(q_t=j|q_{t-1}=i,\\lambda)P(o_t|q_t=j,\\lambda) \\\\\n",
    "&= \\sum^N_{i=1}\\alpha_{t-1}(i)a_{ij}b_j(o_t)\n",
    "\\end{align*}\n",
    "$$\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def likelihood(self,Os):\n",
    "    Length = len(Os)\n",
    "    alpha = np.zeros((self.q,Length))\n",
    "    for t,o in enumerate(Os):\n",
    "        for i in range(self.q):\n",
    "            if t==0:\n",
    "                alpha[i,t]=self.pi[i]*self.B[i][self.o2id[o]]\n",
    "            else:\n",
    "                for j in range(self.q):\n",
    "                    alpha[i,t]+=alpha[j,t-1]*self.A[j][i]\n",
    "                alpha[i,t]*=self.B[i][self.o2id[o]]\n",
    "    return sum(alpha[:,-1]),alpha\n",
    "    \n",
    "hmm.computeLikelihood = lambda x:likelihood(hmm,x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.5049999999999999, array([[0.49 ],\n",
      "       [0.015]]))\n",
      "(0.41000000000000003, array([[0.14],\n",
      "       [0.27]]))\n",
      "(0.049999999999999996, array([[0.035],\n",
      "       [0.015]]))\n",
      "(0.034999999999999996, array([[0.035],\n",
      "       [0.   ]]))\n",
      "(0.25599999999999995, array([[0.49  , 0.2485],\n",
      "       [0.015 , 0.0075]]))\n",
      "(0.20599999999999996, array([[0.49 , 0.071],\n",
      "       [0.015, 0.135]]))\n",
      "(0.2246, array([[0.14  , 0.2198],\n",
      "       [0.27  , 0.0048]]))\n",
      "(0.1492, array([[0.14  , 0.0628],\n",
      "       [0.27  , 0.0864]]))\n"
     ]
    }
   ],
   "source": [
    "print(hmm.computeLikelihood([1]))\n",
    "print(hmm.computeLikelihood([0]))\n",
    "print(hmm.computeLikelihood([2]))\n",
    "print(hmm.computeLikelihood([3]))\n",
    "print(hmm.computeLikelihood([1,1]))\n",
    "print(hmm.computeLikelihood([1,0]))\n",
    "print(hmm.computeLikelihood([0,1]))\n",
    "print(hmm.computeLikelihood([0,0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Decoding: Viterbi Algorithm\n",
    "a. Initialization\n",
    "$$\\begin{align*}\n",
    "v_1(j) &= \\pi_jb_j(o_1) &\\qquad 1\\leq j\\leq N \\\\\n",
    "bt_1(j) &= 0 &\\qquad 1\\leq j\\leq N\n",
    "\\end{align*}\n",
    "$$\n",
    "b. Recursion\n",
    "$$\\begin{align*}\n",
    "v_t(j) &=\\max_{\\{q_k\\}_1^{t-1}} P(\\{q_k\\}_1^{t-1},\\{o_k\\}_1^t,q_t=j | \\lambda) \\\\&= \\max^N_{i=1}v_{t-1}(i)a_{ij}b_j(o_t) &\\qquad 1\\leq j\\leq N\\quad ,\\quad 1<t\\leq T\\\\\n",
    "bt_t(j) &= \\arg\\max^N_{i=1}v_{t-1}(i)a_{ij}b_j(o_t) &\\qquad 1\\leq j\\leq N\\quad ,\\quad 1<t\\leq T\\\\\n",
    "\\end{align*}\n",
    "$$\n",
    "c. Termination\n",
    "$$\\begin{align*}\n",
    "P* &= \\max^N_{i=1}v_T(i) \\\\\n",
    "q_T* &= \\arg\\max^N_{i=1}v_T(i)\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode(self,Os):\n",
    "    Length = len(Os)\n",
    "    V = np.zeros((self.q,Length))\n",
    "    bt = [0]*Length\n",
    "    for t,o in enumerate(Os):\n",
    "        for i in range(self.q):\n",
    "            if t==0:\n",
    "                V[i,t]=self.pi[i]*self.B[i][self.o2id[o]]\n",
    "            else:\n",
    "                for j in range(self.q):\n",
    "                    V[i,t]=max(V[i,t],V[j,t-1]*self.A[j][i])\n",
    "                V[i,t]*=self.B[i][self.o2id[o]]\n",
    "        bt[t]=self.id2q[np.argmax(V[:,t])]\n",
    "    P_ = max(V[:,-1])\n",
    "    return P_,bt\n",
    "hmm.decode = lambda x:decode(hmm,x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.27, ['C'])\n",
      "(0.48999999999999994, ['H'])\n",
      "(0.034999999999999996, ['H'])\n",
      "(0.034999999999999996, ['H'])\n"
     ]
    }
   ],
   "source": [
    "for o in hmm.o2id.keys():\n",
    "    print(hmm.decode([o]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0020995200000000006, ['C', 'C', 'C', 'C'])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hmm.decode([0,0,0,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Learning: HMM Training with Forward-Backward Algorithm\n",
    "> Backward Probability\n",
    "\n",
    "a. Initialization\n",
    "$$\\beta_T(i) = 1 \\qquad 1\\leq i\\leq N$$\n",
    "b. Recursion\n",
    "$$\\begin{align*}\n",
    "\\beta_t(i) &= P(\\{o_k\\}_{t+1}^T|q_t=i,\\lambda) \\\\\n",
    "&=\\sum^N_{j=1}a_{ij}b_j(o_{t+1})\\beta_{t+1}(j) \\qquad 1\\leq i\\leq N\\quad,\\quad 1\\leq t<T\n",
    "\\end{align*}\n",
    "$$\n",
    "c. Termination\n",
    "$$P(O|\\lambda)=\\sum^N_{j=1}\\pi_j b_j(o_1)\\beta_1(j)$$\n",
    "<details >\n",
    "<summary><h4>Click to view proof for Backward probability!</h4></summary>\n",
    "$$\\begin{align*}\n",
    "\\beta_t(i) &= P(\\{o_k\\}_{t+1}^T|q_t=i,\\lambda) = \\sum^N_{j=1}P(q_{t+1}=j,o_{t+1},\\{o_k\\}^T_{t+2}|q_t=i,\\lambda) \\\\\n",
    "&= \\sum^N_{j=1}\\frac{P(q_{t+1}=j,o_{t+1},\\{o_k\\}^T_{t+2},q_t=i|\\lambda)}{P(q_t=i|\\lambda)} \\\\\n",
    "&= \\sum^N_{j=1}\\frac{P(o_{t+1}|q_{t+1}=j,\\{o_k\\}^T_{t+2},q_t=i,\\lambda)\\times\\\\P(\\{o_k\\}^T_{t+2}|q_{t+1}=j,q_t=i,\\lambda)\\times\\\\P(q_{t+1}=j|q_t=i,\\lambda)P(q_t=i|\\lambda)}{P(q_t=i|\\lambda)} \\\\\n",
    "&= \\sum^N_{j=1}P(q_{t+1}=j|q_t=i,\\lambda)P(o_{t+1}|q_{t+1}=j,\\lambda)P(\\{o_k\\}^T_{t+2}|q_{t+1}=j,\\lambda) \\\\\n",
    "&= \\sum^N_{j=1}a_{ij}b_j(o_{t+1})\\beta_{t+1}(j)\n",
    "\\end{align*}$$\n",
    "</details>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def likelihood_backwards(self,Os):\n",
    "    Length = len(Os)\n",
    "    beta = np.zeros((self.q,Length))\n",
    "    for t in range(Length-1,-1,-1):\n",
    "        o = Os[t]\n",
    "        for i in range(self.q):\n",
    "            if t==Length-1:\n",
    "                beta[i,t]=1\n",
    "            else:\n",
    "                for j in range(self.q):\n",
    "                    o_tp1 = self.o2id[Os[t+1]]\n",
    "                    tmp=beta[j,t+1]*self.A[i][j]\n",
    "                    tmp*=self.B[j][o_tp1]\n",
    "                    beta[i,t]+=tmp\n",
    "\n",
    "    P = 0\n",
    "    for j in range(self.q):\n",
    "        P+=self.pi[j]*self.B[j][self.o2id[Os[0]]]*beta[j,0]\n",
    "    return P,beta\n",
    "    \n",
    "hmm.likelihood_backwards = lambda x:likelihood_backwards(hmm,x)\n",
    "               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5049999999999999 0.5049999999999999\n",
      "0.41000000000000003 0.41000000000000003\n",
      "0.049999999999999996 0.049999999999999996\n",
      "0.034999999999999996 0.034999999999999996\n",
      "0.25599999999999995 0.2559999999999999\n",
      "0.20599999999999996 0.206\n",
      "0.2246 0.22459999999999997\n",
      "0.1492 0.14920000000000003\n"
     ]
    }
   ],
   "source": [
    "print(hmm.computeLikelihood([1])[0],\n",
    "      hmm.likelihood_backwards([1])[0])\n",
    "print(hmm.computeLikelihood([0])[0],\n",
    "      hmm.likelihood_backwards([0])[0])\n",
    "print(hmm.computeLikelihood([2])[0],\n",
    "      hmm.likelihood_backwards([2])[0])\n",
    "print(hmm.computeLikelihood([3])[0],\n",
    "      hmm.likelihood_backwards([3])[0])\n",
    "print(hmm.computeLikelihood([1,1])[0],\n",
    "      hmm.likelihood_backwards([1,1])[0])\n",
    "print(hmm.computeLikelihood([1,0])[0],\n",
    "      hmm.likelihood_backwards([1,0])[0])\n",
    "print(hmm.computeLikelihood([0,1])[0],\n",
    "      hmm.likelihood_backwards([0,1])[0])\n",
    "print(hmm.computeLikelihood([0,0])[0],\n",
    "      hmm.likelihood_backwards([0,0])[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sampling from HMM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def samples(self,length):\n",
    "    Qs,Os = [],[]\n",
    "    for i in range(length):\n",
    "        if i==0:\n",
    "            q = np.random.choice(self.q,1,\n",
    "                    p=list(self.pi.values()))\n",
    "        else:\n",
    "            q = np.random.choice(self.q,1,\n",
    "                    p=list(self.A[q[0]].values()))\n",
    "        o = np.random.choice(self.o,1,\n",
    "                    p=list(self.B[q[0]].values()))\n",
    "        Qs.append(self.id2q[q[0]])\n",
    "        Os.append(self.id2o[o[0]])\n",
    "    return Qs,Os\n",
    "\n",
    "hmm.samples = lambda x:samples(hmm,x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['C', 'C', 'H', 'C', 'H', 'H'] ['C', 'C', 'C', 'C', 'H', 'H'] 0.000576108288 [0, 0, 0, 0, 1, 1] 0.00559189888 0.005591898879999998\n",
      "['H', 'H', 'C', 'H', 'H', 'C'] ['H', 'H', 'C', 'H', 'H', 'C'] 0.004802902775999997 [1, 1, 0, 1, 1, 0] 0.011813907699999994 0.011813907699999992\n",
      "['C', 'C', 'H', 'H', 'C', 'H'] ['H', 'C', 'H', 'C', 'C', 'H'] 0.000144027072 [2, 0, 1, 0, 0, 1] 0.0008563935100000001 0.0008563935099999997\n",
      "['H', 'C', 'H', 'H', 'H', 'H'] ['H', 'C', 'H', 'H', 'H', 'C'] 0.0003430644839999998 [1, 0, 1, 2, 1, 0] 0.0012072514999999996 0.0012072514999999999\n",
      "['H', 'H', 'H', 'C', 'H', 'H'] ['C', 'H', 'H', 'C', 'H', 'H'] 0.005489031743999998 [0, 1, 1, 0, 1, 1] 0.012865923699999999 0.012865923699999993\n",
      "['C', 'H', 'H', 'H', 'H', 'C'] ['C', 'H', 'C', 'H', 'H', 'C'] 1.5431472e-05 [0, 1, 0, 3, 2, 0] 6.8314235e-05 6.831423500000002e-05\n",
      "['H', 'H', 'H', 'H', 'C', 'H'] ['H', 'H', 'C', 'H', 'C', 'C'] 0.00012602368800000003 [3, 1, 0, 1, 0, 0] 0.00058717435 0.0005871743500000001\n",
      "['H', 'H', 'H', 'C', 'C', 'H'] ['H', 'H', 'H', 'C', 'C', 'H'] 0.00022870965599999994 [1, 1, 1, 0, 0, 2] 0.00096380675 0.0009638067499999998\n",
      "['C', 'C', 'H', 'H', 'C', 'H'] ['C', 'C', 'C', 'H', 'C', 'H'] 7.054387200000003e-05 [0, 0, 0, 1, 0, 3] 0.00046829852 0.00046829852000000006\n",
      "['H', 'C', 'H', 'H', 'H', 'C'] ['H', 'C', 'H', 'H', 'H', 'H'] 4.447132199999998e-05 [1, 0, 1, 2, 1, 2] 0.00014787631249999996 0.00014787631249999994\n"
     ]
    }
   ],
   "source": [
    "N = 10\n",
    "for i in range(N):\n",
    "    Qs,Os = hmm.samples(6)\n",
    "    l,alpha = hmm.computeLikelihood(Os)\n",
    "    lB,beta = hmm.likelihood_backwards(Os)\n",
    "    lQ,dQs = hmm.decode(Os)\n",
    "    print(Qs,dQs,lQ,Os,l,lB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Transition Probability Matrix $A$\n",
    "\n",
    "$$\\begin{align*}\n",
    "    \\hat{a}_{ij}&=\\frac{\\sum^{T-1}_{t=1}\\xi_t(i,j)}{\\sum^{T-1}_{t=1}\\sum^N_{k=1}\\xi_t(i,k)}\\\\\n",
    "    \\xi_t(i,j) &= \\frac{\\alpha_t(i)a_{ij}b_j(o_{t+1})\\beta_{t+1}(j)}{\\sum^N_{j=1}\\alpha_t(j)\\beta_t(j)}\n",
    "\\end{align*}$$\n",
    "<details >\n",
    "<summary><h4>Click to view proof for transition probability!</h4></summary>\n",
    "\n",
    "</details>\n",
    "\n",
    "> Emission Probabilities $B$\n",
    "\n",
    "$$\\begin{align*}\n",
    "\\hat{b}_j(v_k) &= \\frac{\\sum^T_{t=1 s.t.O_t=v_k}\\gamma_t(j)}{\\sum^T_{t=1}\\gamma_t(j)} \\\\\n",
    "\\gamma_t(j) &= \\frac{\\alpha_t(j)\\beta_t(j)}{\\sum^N_{j=1}\\alpha_t(j)\\beta_t(j)}\n",
    "\\end{align*}$$\n",
    "<details >\n",
    "<summary><h4>Click to view proof for emission probability!</h4></summary>\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def e_step(self,Os):\n",
    "    Length = len(Os)\n",
    "    l,alpha = self.computeLikelihood(Os)\n",
    "    lB,beta = self.likelihood_backwards(Os)\n",
    "    alphabeta = alpha*beta\n",
    "    sum_alphabeta = np.sum(alphabeta,axis=0)\n",
    "    gamma = alphabeta/sum_alphabeta\n",
    "    xi = np.zeros((Length,self.q,self.q))\n",
    "    for t in range(Length-1):\n",
    "        o_tp1 = self.o2id[Os[t+1]]\n",
    "        for i in range(self.q):\n",
    "            for j in range(self.q):\n",
    "                tmp=alpha[i,t]*beta[j,t+1]\n",
    "                tmp*=self.A[i][j]*self.B[j][o_tp1]\n",
    "                xi[t,i,j]=tmp/sum_alphabeta[t]\n",
    "    return l,gamma,xi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def m_step(self,Os,gamma,xi):\n",
    "    atop = np.sum(xi[:-1,:,:],axis=0)\n",
    "    abottom = np.sum(atop,axis=1,keepdims=1)\n",
    "    Os = np.array(Os)\n",
    "    btop = np.zeros((self.o,self.q))\n",
    "    for o in range(self.o):\n",
    "        tmp = gamma[:,Os==self.id2o[o]].sum(axis=1)\n",
    "        btop[o,:] = tmp\n",
    "    bbottom = gamma.sum(axis=1)\n",
    "    return atop,abottom,btop,bbottom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update(self,A,B,pi):\n",
    "    for i in range(self.q):\n",
    "        for j in range(self.q):\n",
    "            self.A[i][j]=A[i,j]\n",
    "        self.pi[i]=pi[i]\n",
    "        for o in range(self.o):\n",
    "            self.B[i][o]=B[o,i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def learn(self,Osamples,iters=10):\n",
    "    ls = []\n",
    "    for _ in tqdm(range(iters)):\n",
    "        tmp,at,ab,bt,bb,pt = 0,0,0,0,0,0\n",
    "        for Os in Osamples:\n",
    "            l,gamma,xi = self.e_step(Os)\n",
    "            tmp+=l\n",
    "            atop,abottom,btop,bbottom = self.m_step(Os,gamma,xi)\n",
    "            at+=atop\n",
    "            ab+=abottom\n",
    "            bt+=btop\n",
    "            bb+=bbottom\n",
    "            pt+=gamma[:,0]\n",
    "        ls.append(tmp/N)\n",
    "        pi = pt/N\n",
    "        A = at/ab\n",
    "        B = bt/bb\n",
    "        self.update(A,B,pi)\n",
    "    return ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_patch(obj):\n",
    "    obj.computeLikelihood = lambda x:likelihood(obj,x)\n",
    "    obj.decode = lambda x:decode(obj,x)\n",
    "    obj.likelihood_backwards = lambda x:likelihood_backwards(obj,x)\n",
    "    obj.samples = lambda x:samples(obj,x)\n",
    "    obj.e_step = lambda x:e_step(obj,x)\n",
    "    obj.m_step = lambda x,y,z: m_step(obj,x,y,z)  \n",
    "    obj.update = lambda x,y,z: update(obj,x,y,z)\n",
    "    obj.learn = lambda x,y: learn(obj,x,y)\n",
    "    return obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "hmm = add_patch(hmm)\n",
    "N,T = 1000,6\n",
    "Osamples = []\n",
    "for _ in range(N):\n",
    "    Qs,Os = hmm.samples(T)\n",
    "    Osamples.append(Os)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 1, 0, 0, 2, 1], [0, 1, 1, 1, 0, 2], [3, 0, 1, 1, 0, 1]]\n"
     ]
    }
   ],
   "source": [
    "print(Osamples[0:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = HMM()\n",
    "model.setDistinctHiddensAndObservations([0,1,2,3],[\"H\",\"C\"])\n",
    "model = add_patch(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<class 'dict'>, {0: {0: 0.27598362460892506, 1: 0.724016375391075}, 1: {0: 0.5013706614085423, 1: 0.49862933859145786}})\n",
      "defaultdict(<class 'dict'>, {0: {0: 0.5443808888985004, 1: 0.3033362788273822, 2: 0.12024252800943273, 3: 0.032040304264684634}, 1: {0: 0.2990199978975486, 1: 0.5255697653609589, 2: 0.13800031157842993, 3: 0.03740992516306255}})\n",
      "{0: 0.8155274069343782, 1: 0.18447259306562178}\n"
     ]
    }
   ],
   "source": [
    "print(model.A)\n",
    "print(model.B)\n",
    "print(model.pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 11.12it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f4b9c29ca90>]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "iters = 10\n",
    "ls = model.learn(Osamples,iters)\n",
    "plt.plot(range(iters),ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<class 'dict'>, {0: {0: 0.2776440717125321, 1: 0.7223559282874671}, 1: {0: 0.5129663961349196, 1: 0.4870336038650777}})\n",
      "defaultdict(<class 'dict'>, {0: {0: 0.5028424147483609, 1: 0.40213675664317416, 2: 0.05541431048363899, 3: 0.0396065181248238}, 1: {0: 0.31566145542028834, 1: 0.6035400248517026, 2: 0.046014210209111756, 3: 0.03478430951889797}})\n",
      "{0: 0.7423630004191993, 1: 0.25763699958080183}\n"
     ]
    }
   ],
   "source": [
    "print(model.A)\n",
    "print(model.B)\n",
    "print(model.pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<class 'dict'>, {0: {0: 0.7, 1: 0.3}, 1: {0: 0.8, 1: 0.2}})\n",
      "defaultdict(<class 'dict'>, {0: {0: 0.2, 1: 0.7, 2: 0.05, 3: 0.05}, 1: {0: 0.9, 1: 0.05, 2: 0.05, 3: 0}})\n",
      "{0: 0.7, 1: 0.3}\n"
     ]
    }
   ],
   "source": [
    "print(hmm.A)\n",
    "print(hmm.B)\n",
    "print(hmm.pi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References\n",
    "- https://web.stanford.edu/~jurafsky/slp3/A.pdf\n",
    "- https://en.wikipedia.org/wiki/Baum%E2%80%93Welch_algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
