{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(400,) (400,)\n",
      "[[0 1 2 3 4]\n",
      " [0 1 2 3 4]\n",
      " [0 1 2 3 4]\n",
      " [0 1 2 3 4]\n",
      " [0 1 2 3 4]]\n",
      "[[0 0 0 0 0]\n",
      " [1 1 1 1 1]\n",
      " [2 2 2 2 2]\n",
      " [3 3 3 3 3]\n",
      " [4 4 4 4 4]]\n",
      "(400, 400) (400, 400)\n",
      "(400, 400, 3)\n",
      "(160000, 3)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "H, W, f = 400, 400, 1200\n",
    "rays_o = np.zeros((H*W,3))\n",
    "rays_d = np.zeros((H*W,3))\n",
    "u = np.arange(H)\n",
    "v = np.arange(W)\n",
    "print(u.shape, v.shape)\n",
    "u,v = np.meshgrid(u,v)\n",
    "print(u[:5,:5])\n",
    "print(v[:5,:5])\n",
    "print(u.shape,v.shape)\n",
    "dirs = np.stack(((u-W/2), \n",
    "               -(v-H/2),\n",
    "               -np.ones_like(u)*f), \n",
    "                axis=-1) # depth fo focal length\n",
    "rays_d = dirs/np.linalg.norm(dirs, axis=-1, keepdims=True)\n",
    "# center of projection to image plane\n",
    "print(dirs.shape)\n",
    "rays_d = rays_d.reshape(-1, 3)\n",
    "print(rays_d.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- NeRF: Representing Scenes as Neural Radiance Fields for View Synthesis\n",
    "    - https://arxiv.org/pdf/2003.08934.pdf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Radiance Field Scene Representation\n",
    "A continuous scene is represented as a 5D vector-value function whose input is a 3D location $\\mathbf{x}=(x,y,z)$ and 2D viewing direction $(\\theta, \\phi)$ and whose output is an emitted color $\\mathbf{c} = (r,g,b)$ and volume density $\\sigma$.\n",
    "\n",
    "In practice, direction is expressed as a 3D Cartesian unit vector $\\mathbf{d}$. The continuous 5D scene representation is approximated with an MLP network $\\mathcal{F}_\\mathcal{\\theta}: (\\mathbf{x},\\mathbf{d})\\rightarrow (\\mathbf{c},\\sigma)$ and it should be optimised with weights $\\theta$ to map from each input 5D coordinate to its corresponding volume density and directional emitted color."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
