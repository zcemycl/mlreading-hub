{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package words to /home/yui/nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/yui/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/yui/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import pairwise_distances\n",
    "import pandas as pd\n",
    "import math\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "from nltk import word_tokenize\n",
    "nltk.download('words')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from tqdm import tqdm,tqdm_pandas\n",
    "from gensim.models import KeyedVectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Glove \n",
    "- http://nlp.stanford.edu/data/glove.6B.zip\n",
    "\n",
    "#### Word2Vec\n",
    "- https://drive.google.com/u/0/uc?id=0B7XkCwpI5KDYNlNUTTlSS21pQmM&export=download\n",
    "- Need a package named gensim `pip install gensim`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadGlove(PATH):\n",
    "    d,w2id,id2w = {},{},{}\n",
    "    with open(PATH,'r') as f:\n",
    "        lines = f.readlines()\n",
    "        D = len(lines[0].split(\" \")[1:])\n",
    "        wmat = np.zeros((len(lines),D))\n",
    "        for i,line in enumerate(tqdm(lines)):\n",
    "            tokens = line.split(\" \")\n",
    "            word = tokens[0]\n",
    "            w2id[word]=i\n",
    "            id2w[i]=word\n",
    "            vec = np.array(list(map(float,tokens[1:])))\n",
    "            d[i]=vec\n",
    "            wmat[i]=vec\n",
    "    return d,w2id,id2w,wmat,D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Word Analogies with Embeddings\n",
    "$$\\begin{align*}\n",
    "v-v_a &\\approx v_b-v_c\\\\\n",
    "\\min_v d&=\\min_v |v-v_a-v_b+v_c|\\\\\n",
    "\\end{align*}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class wordAnalogies:\n",
    "    def __init__(self,PATH):\n",
    "        self.PATH = PATH\n",
    "        self.dGlove,self.w2id,self.id2w,\\\n",
    "            self.wmat,self.D = loadGlove(PATH)\n",
    "    def find(self,a,b,c):\n",
    "        v_ = self.dGlove[self.w2id[a]]+\\\n",
    "            self.dGlove[self.w2id[b]]-\\\n",
    "            self.dGlove[self.w2id[c]]\n",
    "        v_ = v_.reshape(1,self.D)\n",
    "        distances = pairwise_distances(v_,\n",
    "            self.wmat).reshape(-1)\n",
    "        closestId = np.argmin(distances)\n",
    "        closestW = self.id2w[closestId]\n",
    "        print(\"Closest word to {}+{}-{}: {}\".format(\\\n",
    "                a,b,c,closestW))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400000/400000 [00:03<00:00, 126119.32it/s]\n"
     ]
    }
   ],
   "source": [
    "PATH = \"/home/yui/Documents/data/nlp/glove.6B/glove.6B.50d.txt\"\n",
    "wa = wordAnalogies(PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closest word to woman+boy-girl: man\n",
      "Closest word to korean+japan-japanese: korea\n"
     ]
    }
   ],
   "source": [
    "wa.find(\"woman\",\"boy\",\"girl\")\n",
    "wa.find(\"korean\",\"japan\",\"japanese\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
