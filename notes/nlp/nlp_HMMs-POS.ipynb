{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "from mlreading_hub.pml.mle_hmm import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadData(PATH):\n",
    "    words,tags = [],[]\n",
    "    vocab,vocabtag = set(),set()\n",
    "    with open(PATH) as f:\n",
    "        lines = f.readlines()\n",
    "        sent,senttag = [],[]\n",
    "        for line in lines:\n",
    "            line = line.strip()\n",
    "            tokens = line.split(\" \")\n",
    "            if len(tokens)>1:\n",
    "                sent.append(tokens[0])\n",
    "                senttag.append(tokens[1])\n",
    "                vocab.add(tokens[0])\n",
    "                vocabtag.add(tokens[1])\n",
    "            else:\n",
    "                words.append(sent)\n",
    "                tags.append(senttag)\n",
    "                sent,senttag=[],[]        \n",
    "    return words,tags,vocab,vocabtag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part of Speech Tagging\n",
    "- https://www.clips.uantwerpen.be/conll2000/chunking/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDataPATH = \"/home/yui/Documents/data/nlp/pos/train.txt\"\n",
    "words,tags,vocab,vocabtag = loadData(trainDataPATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "testDataPATH = \"/home/yui/Documents/data/nlp/pos/test.txt\"\n",
    "words_,tags_,_,_ = loadData(testDataPATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of vocabularies:  19122\n",
      "Number of tags:  44\n",
      "Number of sentences for training:  8936 8936\n",
      "Number of sentences for testing:  2012 2012\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of vocabularies: \",len(vocab))\n",
    "print(\"Number of tags: \",len(vocabtag))\n",
    "print(\"Number of sentences for training: \",len(words),len(tags))\n",
    "print(\"Number of sentences for testing: \",len(words_),len(tags_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8936/8936 [46:25<00:00,  3.21it/s]\n"
     ]
    }
   ],
   "source": [
    "model = HMM()\n",
    "model.setDistinctHiddensAndObservations(list(vocab),\n",
    "            list(vocabtag))\n",
    "model = add_patch(model)\n",
    "for i in tqdm(range(len(words))):\n",
    "    model.learn(tags[i],words[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Metrics\n",
    "1. Accuracy $\\frac{TP+TN}{TP+TN+FP+FN}$\n",
    "2. Precision $\\frac{TP}{TP+FP}$\n",
    "3. Recall $\\frac{TP}{TP+FN}$\n",
    "4. F1 score $2\\frac{P\\times R}{P+R}$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evalPerformance(model,words,tags,name=\"Train\"):\n",
    "    TP,total = 0,0\n",
    "    for i in tqdm(range(len(words))):\n",
    "        try:\n",
    "            _,res = model.decode(words[i])\n",
    "            for j in range(len(res)):\n",
    "                TP += res[j]==tags[i][j]\n",
    "                total+=1\n",
    "        except:\n",
    "            pass\n",
    "    print(\"{} Accuracy: \".format(name),TP/total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8936/8936 [04:37<00:00, 32.21it/s]\n",
      "  1%|          | 22/2012 [00:00<00:28, 69.33it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy:  0.9231415927113689\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2012/2012 [00:27<00:00, 74.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy:  0.9368231046931408\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "evalPerformance(model,words,tags,name=\"Train\")\n",
    "evalPerformance(model,words_,tags_,name=\"Test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
