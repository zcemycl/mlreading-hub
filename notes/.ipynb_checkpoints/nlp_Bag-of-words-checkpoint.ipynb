{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package words to /home/yui/nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/yui/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/yui/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "0it [00:00, ?it/s]\n",
      "TqdmDeprecationWarning: Please use `tqdm.pandas(...)` instead of `tqdm_pandas(tqdm(...))`.\n",
      "/home/yui/anaconda3/lib/python3.7/site-packages/tqdm/std.py:658: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n",
      "  from pandas import Panel\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import pairwise_distances\n",
    "import pandas as pd\n",
    "import math\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "from nltk import word_tokenize\n",
    "nltk.download('words')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from tqdm import tqdm,tqdm_pandas\n",
    "from gensim.models import KeyedVectors\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "tqdm_pandas(tqdm())\n",
    "\n",
    "pd.set_option('display.expand_frame_repr', False)\n",
    "PATH=\"/home/yui/Documents/data/nlp/covidTweet/Corona_NLP_train.csv\"\n",
    "df = pd.read_csv(PATH, encoding = \"ISO-8859-1\")\n",
    "df = df[[\"OriginalTweet\",\"Sentiment\"]]\n",
    "\n",
    "def loadGlove(PATH):\n",
    "    d,w2id,id2w = {},{},{}\n",
    "    with open(PATH,'r') as f:\n",
    "        lines = f.readlines()\n",
    "        D = len(lines[0].split(\" \")[1:])\n",
    "        wmat = np.zeros((len(lines),D))\n",
    "        for i,line in enumerate(lines):\n",
    "            tokens = line.split(\" \")\n",
    "            word = tokens[0]\n",
    "            w2id[word]=i\n",
    "            id2w[i]=word\n",
    "            vec = np.array(list(map(float,tokens[1:])))\n",
    "            d[i]=vec\n",
    "            wmat[i]=vec\n",
    "    return d,w2id,id2w,wmat,D\n",
    "PATH = \"/home/yui/Documents/data/nlp/glove.6B/glove.6B.50d.txt\"\n",
    "d,w2id,id2w,wmat,D = loadGlove(PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class preprocessPipe:\n",
    "    def __init__(self):\n",
    "        self.eng = set(nltk.corpus.words.words())\n",
    "        self.lem = WordNetLemmatizer()\n",
    "        self.w2d = dict() # word:({docid:count,...},nt)\n",
    "        self.s2id = dict()\n",
    "    def get_wordnet_pos(self,word):\n",
    "        \"\"\"Map POS tag to first character lemmatize() accepts\"\"\"\n",
    "        tag = nltk.pos_tag([word])[0][1][0].upper()\n",
    "        tag_dict = {\"J\": wordnet.ADJ,\n",
    "                    \"N\": wordnet.NOUN,\n",
    "                    \"V\": wordnet.VERB,\n",
    "                    \"R\": wordnet.ADV}\n",
    "        return tag_dict.get(tag,wordnet.NOUN)\n",
    "    def lemmWord(self,w):\n",
    "        return self.lem.lemmatize(w,\n",
    "                self.get_wordnet_pos(w))\n",
    "    def tokenSentence(self,s):\n",
    "        return nltk.wordpunct_tokenize(s)\n",
    "    def sent2id(self,sentence):\n",
    "        ind = len(self.s2id)+1\n",
    "        self.s2id[sentence]=ind\n",
    "        return ind\n",
    "    def run(self,sentence):\n",
    "        sentence = sentence.lower()\n",
    "        ind = self.sent2id(sentence)\n",
    "        tokens = self.tokenSentence(sentence)\n",
    "        vec,lenEng = 0,0\n",
    "        for w in tokens:\n",
    "            if w not in self.eng:\n",
    "                continue\n",
    "            w = self.lemmWord(w)\n",
    "            if w not in w2id:\n",
    "                continue\n",
    "            vec+=d[w2id[w]]\n",
    "            lenEng+=1\n",
    "        if lenEng==0:\n",
    "            return np.zeros(D),lenEng\n",
    "        return vec/lenEng,lenEng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "41157it [00:59, 692.74it/s]\n"
     ]
    }
   ],
   "source": [
    "pp = preprocessPipe()\n",
    "df[\"Input\"],df[\"Counts\"]=zip(*df[\"OriginalTweet\"]\\\n",
    "                    .progress_apply(pp.run))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bag of words\n",
    "- Embedding $v$ of the sentence $s$ is given by, \n",
    "\n",
    "$$v(s) = \\frac{1}{|s|}\\sum_{w\\in s}v(w)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordLim = 5\n",
    "df = df[df[\"Counts\"]>wordLim]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Positive', 'Extremely Negative', 'Neutral', 'Negative', 'Extremely Positive']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OriginalTweet</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Input</th>\n",
       "      <th>Counts</th>\n",
       "      <th>Output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>advice Talk to your neighbours family to excha...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>(0.33271789285714287, 0.17252346428571425, 0.1...</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Coronavirus Australia: Woolworths to give elde...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>(0.4782337499999999, 0.07637737499999996, 0.28...</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>My food stock is not the only one which is emp...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>(0.38000114054054046, 0.03723013513513513, 0.1...</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Me, ready to go at supermarket during the #COV...</td>\n",
       "      <td>Extremely Negative</td>\n",
       "      <td>(0.31456214, 0.017596571428571423, 0.059678925...</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>As news of the regionÂs first confirmed COVID...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>(0.31297992857142853, 0.10409821428571424, 0.0...</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       OriginalTweet           Sentiment                                              Input  Counts  Output\n",
       "1  advice Talk to your neighbours family to excha...            Positive  (0.33271789285714287, 0.17252346428571425, 0.1...      28       0\n",
       "2  Coronavirus Australia: Woolworths to give elde...            Positive  (0.4782337499999999, 0.07637737499999996, 0.28...       8       0\n",
       "3  My food stock is not the only one which is emp...            Positive  (0.38000114054054046, 0.03723013513513513, 0.1...      37       0\n",
       "4  Me, ready to go at supermarket during the #COV...  Extremely Negative  (0.31456214, 0.017596571428571423, 0.059678925...      35       1\n",
       "5  As news of the regionÂs first confirmed COVID...            Positive  (0.31297992857142853, 0.10409821428571424, 0.0...      28       0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = list(df[\"Sentiment\"].unique())\n",
    "print(labels)\n",
    "df[\"Output\"]=df[\"Sentiment\"].apply(lambda x:labels.index(x))\n",
    "df[\"Output\"]=df[\"Output\"].apply(lambda x:0 if x in [0,2,3] else 1)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = list(df[\"Input\"])\n",
    "Y = list(df[\"Output\"])\n",
    "clf = LogisticRegression(max_iter=1000).fit(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7034127301841473"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
