{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package words to /home/yui/nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/yui/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/yui/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "0it [00:00, ?it/s]\n",
      "TqdmDeprecationWarning: Please use `tqdm.pandas(...)` instead of `tqdm_pandas(tqdm(...))`.\n",
      "/home/yui/anaconda3/lib/python3.7/site-packages/tqdm/std.py:658: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n",
      "  from pandas import Panel\n",
      "41157it [01:01, 671.14it/s]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import pairwise_distances\n",
    "import pandas as pd\n",
    "import math\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "from nltk import word_tokenize\n",
    "nltk.download('words')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from tqdm import tqdm,tqdm_pandas\n",
    "\n",
    "tqdm_pandas(tqdm())\n",
    "\n",
    "pd.set_option('display.expand_frame_repr', False)\n",
    "PATH=\"/home/yui/Documents/data/nlp/covidTweet/Corona_NLP_train.csv\"\n",
    "df = pd.read_csv(PATH, encoding = \"ISO-8859-1\")\n",
    "df = df[[\"OriginalTweet\",\"Sentiment\"]]\n",
    "\n",
    "def loadGlove(PATH):\n",
    "    d,w2id,id2w = {},{},{}\n",
    "    with open(PATH,'r') as f:\n",
    "        lines = f.readlines()\n",
    "        D = len(lines[0].split(\" \")[1:])\n",
    "        wmat = np.zeros((len(lines),D))\n",
    "        for i,line in enumerate(lines):\n",
    "            tokens = line.split(\" \")\n",
    "            word = tokens[0]\n",
    "            w2id[word]=i\n",
    "            id2w[i]=word\n",
    "            vec = np.array(list(map(float,tokens[1:])))\n",
    "            d[i]=vec\n",
    "            wmat[i]=vec\n",
    "    return d,w2id,id2w,wmat,D\n",
    "\n",
    "class preprocessPipe:\n",
    "    def __init__(self):\n",
    "        self.eng = set(nltk.corpus.words.words())\n",
    "        self.lem = WordNetLemmatizer()\n",
    "        self.w2d = dict() # word:({docid:count,...},nt)\n",
    "        self.s2id = dict()\n",
    "    def get_wordnet_pos(self,word):\n",
    "        \"\"\"Map POS tag to first character lemmatize() accepts\"\"\"\n",
    "        tag = nltk.pos_tag([word])[0][1][0].upper()\n",
    "        tag_dict = {\"J\": wordnet.ADJ,\n",
    "                    \"N\": wordnet.NOUN,\n",
    "                    \"V\": wordnet.VERB,\n",
    "                    \"R\": wordnet.ADV}\n",
    "        return tag_dict.get(tag,wordnet.NOUN)\n",
    "    def lemmWord(self,w):\n",
    "        return self.lem.lemmatize(w,\n",
    "                self.get_wordnet_pos(w))\n",
    "    def tokenSentence(self,s):\n",
    "        return nltk.wordpunct_tokenize(s)\n",
    "    def sent2id(self,sentence):\n",
    "        ind = len(self.s2id)+1\n",
    "        self.s2id[sentence]=ind\n",
    "        return ind\n",
    "    def run(self,sentence):\n",
    "        sentence = sentence.lower()\n",
    "        ind = self.sent2id(sentence)\n",
    "        tokens = self.tokenSentence(sentence)\n",
    "        vec,lenEng = 0,0\n",
    "        for w in tokens:\n",
    "            if w not in self.eng:\n",
    "                continue\n",
    "            w = self.lemmWord(w)\n",
    "            if w not in w2id:\n",
    "                continue\n",
    "            vec+=d[w2id[w]]\n",
    "            lenEng+=1\n",
    "        if lenEng==0:\n",
    "            return np.zeros(D),lenEng\n",
    "        return vec/lenEng,lenEng\n",
    "    \n",
    "PATH = \"/home/yui/Documents/data/nlp/glove.6B/glove.6B.50d.txt\"\n",
    "d,w2id,id2w,wmat,D = loadGlove(PATH)\n",
    "\n",
    "pp = preprocessPipe()\n",
    "df[\"Input\"],df[\"Counts\"]=zip(*df[\"OriginalTweet\"]\\\n",
    "                    .progress_apply(pp.run))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"CountWords\"]=df[\"OriginalTweet\"].apply(lambda x:len(x.split(\" \")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    41157.000000\n",
       "mean        30.327818\n",
       "std         11.633754\n",
       "min          1.000000\n",
       "25%         21.000000\n",
       "50%         31.000000\n",
       "75%         40.000000\n",
       "max        127.000000\n",
       "Name: CountWords, dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"CountWords\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OriginalTweet</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Input</th>\n",
       "      <th>Counts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@MeNyrbie @Phil_Gahan @Chrisitv https://t.co/i...</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>(-0.120218, 0.428472, 0.464072, 0.5489208, 0.2...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>advice Talk to your neighbours family to excha...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>(0.33271789285714287, 0.17252346428571425, 0.1...</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Coronavirus Australia: Woolworths to give elde...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>(0.4782337499999999, 0.07637737499999996, 0.28...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>My food stock is not the only one which is emp...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>(0.38000114054054046, 0.03723013513513513, 0.1...</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Me, ready to go at supermarket during the #COV...</td>\n",
       "      <td>Extremely Negative</td>\n",
       "      <td>(0.31456214, 0.017596571428571423, 0.059678925...</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       OriginalTweet           Sentiment                                              Input  Counts\n",
       "0  @MeNyrbie @Phil_Gahan @Chrisitv https://t.co/i...             Neutral  (-0.120218, 0.428472, 0.464072, 0.5489208, 0.2...       5\n",
       "1  advice Talk to your neighbours family to excha...            Positive  (0.33271789285714287, 0.17252346428571425, 0.1...      28\n",
       "2  Coronavirus Australia: Woolworths to give elde...            Positive  (0.4782337499999999, 0.07637737499999996, 0.28...       8\n",
       "3  My food stock is not the only one which is emp...            Positive  (0.38000114054054046, 0.03723013513513513, 0.1...      37\n",
       "4  Me, ready to go at supermarket during the #COV...  Extremely Negative  (0.31456214, 0.017596571428571423, 0.059678925...      35"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    41157.000000\n",
       "mean        23.341497\n",
       "std         10.568691\n",
       "min          0.000000\n",
       "25%         15.000000\n",
       "50%         24.000000\n",
       "75%         31.000000\n",
       "max         61.000000\n",
       "Name: Counts, dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Counts.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 41157/41157 [00:00<00:00, 100101.11it/s]\n"
     ]
    }
   ],
   "source": [
    "originalTweets = df[\"OriginalTweet\"]\n",
    "vocab,maxLen = set(),0\n",
    "for i in tqdm(range(len(df))):\n",
    "    ele = originalTweets.iloc[i].lower()\n",
    "    tokens = list(filter(lambda x:x in pp.eng,ele.split(\" \")))\n",
    "    if len(tokens)>maxLen:\n",
    "        maxLen=len(tokens)\n",
    "    vocab|=set(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12010 55\n"
     ]
    }
   ],
   "source": [
    "print(len(vocab),maxLen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([20, 33, 24])\n"
     ]
    }
   ],
   "source": [
    "m = nn.Conv1d(16, 33, 3, stride=2)\n",
    "input = torch.randn(20, 16, 50)\n",
    "output = m(input)\n",
    "print(output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([20, 33, 24, 49])\n"
     ]
    }
   ],
   "source": [
    "m = nn.Conv2d(16, 33, 3, stride=2)\n",
    "input = torch.randn(20, 16, 50, 100)\n",
    "output = m(input)\n",
    "print(output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
