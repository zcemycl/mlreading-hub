{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hidden Markov Models (HMMs)\n",
    "$$\\begin{align*}P(O) &= \\sum_Q P(O,Q)=\\sum_Q P(O|Q)P(Q) \\\\ &= \\sum_{j=1}^N \\prod^T_{i=1}P(o_i|q_i)P(q_i|q_{i-1})= \\sum_{j=1}^N \\prod^T_{i=1}a_{ij}b(o_i)\n",
    "\\end{align*}$$\n",
    "It is useful for 3 fundamental problems, \n",
    "1. Likelihood \n",
    "<p> Given an HMM $\\lambda = (A,B)$ and an observation sequence $O$, determine the likelihood $P(O|\\lambda)$. </p>\n",
    "2. Decoding\n",
    "<p> Given an observation sequence $O$ and and HMM $\\lambda=(A,B)$, discover the best hidden state sequence Q. </p>\n",
    "3. Learning\n",
    "<p> Given an observation sequence $O$ and the set of states in the HMM, learn the HMM parameters $A$ and $B$. </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HMM:\n",
    "    def __init__(self):\n",
    "        self.params = defaultdict(dict)\n",
    "        self.o2id,self.id2o = dict(),dict()\n",
    "        self.q2id,self.id2q = dict(),dict()\n",
    "    def _setDistinctObservations(self,distO):\n",
    "        self.o = len(distO)\n",
    "        for i,o in enumerate(distO):\n",
    "            self.o2id[o]=i\n",
    "            self.id2o[i]=o\n",
    "    def _setDistinctHiddens(self,distQ):\n",
    "        self.q = len(distQ)\n",
    "        A = np.random.uniform(0,1,(self.q,self.q))\n",
    "        A /= np.sum(A,axis=1,keepdims=1)\n",
    "        B = np.random.uniform(0,1,(self.q,self.o))\n",
    "        B /= np.sum(B,axis=1,keepdims=1)\n",
    "        pi = np.random.uniform(0,1,self.q)\n",
    "        pi/= np.sum(pi)\n",
    "        self.A = defaultdict(dict)\n",
    "        self.B = defaultdict(dict)\n",
    "        self.pi = {}\n",
    "        for i,q in enumerate(distQ):\n",
    "            self.q2id[q]=i\n",
    "            self.id2q[i]=q\n",
    "            for j,q_ in enumerate(distQ):\n",
    "                self.A[i][j] = A[i][j]\n",
    "            for k in range(self.o):\n",
    "                self.B[i][k] = B[i][k]\n",
    "            self.pi[i] = pi[i]\n",
    "    def setDistinctHiddensAndObservations(self,distO,distQ):\n",
    "        self._setDistinctObservations(distO)\n",
    "        self._setDistinctHiddens(distQ)\n",
    "    def setSpecificEmit(self,qSym,emitDict):\n",
    "        assert sum(emitDict.values())==1, \"Sum of probability is not 1\"\n",
    "        for i in self.B[self.q2id[qSym]].keys():\n",
    "            # assert in dict\n",
    "            self.B[self.q2id[qSym]][i]=emitDict.get(self.id2o[i],0)\n",
    "        assert sum(self.B[self.q2id[qSym]].values())==1, \"Sum of probability is not 1\"\n",
    "    def setSpecificTransit(self,qSym,tranDict):\n",
    "        assert sum(tranDict.values())==1, \"Sum of probability is not 1\"\n",
    "        for i in self.A[self.q2id[qSym]].keys():\n",
    "            self.A[self.q2id[qSym]][i]=tranDict.get(self.id2q[i],0)\n",
    "        assert sum(self.A[self.q2id[qSym]].values())==1, \"Sum of probability is not 1\"\n",
    "    def setInitial(self,initDict):\n",
    "        assert sum(initDict.values())==1, \"Sum of probability is not 1\"\n",
    "        for i in self.pi.keys():\n",
    "            # assert in dict\n",
    "            self.pi[i]=initDict.get(self.id2q[i],0)\n",
    "        assert sum(self.pi.values())==1, \"Sum of probability is not 1\"\n",
    "    def computeLikelihood(self,Os):\n",
    "        raise NotImplementedError(\"You need to implement function1 when you inherit from Model\")\n",
    "    def decode(self,Os):\n",
    "        raise NotImplementedError(\"You need to implement function1 when you inherit from Model\")\n",
    "    def learn(self,Qs,Os):\n",
    "        raise NotImplementedError(\"You need to implement function1 when you inherit from Model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "hmm = HMM()\n",
    "hmm.setDistinctHiddensAndObservations([0,1,2,3],[\"H\",\"C\"])\n",
    "hmm.setInitial({\"H\":0.7,\"C\":0.3})\n",
    "hmm.setSpecificTransit(\"H\",{\"H\":0.7,\"C\":0.3})\n",
    "hmm.setSpecificTransit(\"C\",{\"H\":0.8,\"C\":0.2})\n",
    "hmm.setSpecificEmit(\"H\",{0:0.2,1:0.7,2:0.05,3:0.05})\n",
    "hmm.setSpecificEmit(\"C\",{0:0.9,1:0.05,2:0.05})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Likelihood: Forward Algorithm\n",
    "a. Initialization\n",
    "$$\\alpha_1(j) = \\pi_jb_j(o_1) \\qquad 1\\leq j\\leq N$$\n",
    "b. Recursion\n",
    "$$\\begin{align*}\\alpha_t(j) &= P(\\{o_i\\}_{i=1}^t, q_t=j|\\lambda) \\\\ \n",
    "&= \\sum^N_{i=1}\\alpha_{t-1}(i)a_{ij}b_j(o_t) \\qquad 1\\leq j\\leq N\\quad ,\\quad 1<t\\leq T \\end{align*}$$\n",
    "c. Termination\n",
    "$$\n",
    "P(O|\\lambda) = \\sum^N_{i=1}\\alpha_T(i)\n",
    "$$\n",
    "<details>\n",
    "<summary><h4>Click to view proof for Forward probability!</h4></summary>\n",
    "$$\\begin{align*}\n",
    "\\alpha_t(j) &= P(\\{o_k\\}^t_1,q_t=j|\\lambda) = \\sum^N_{i=1} P(\\{o_k\\}^{t-1}_1,o_t,q_t=j,q_{t-1}=i|\\lambda)\\\\\n",
    "&= \\sum^N_{i=1}P(o_t|\\{o_k\\}^{t-1}_1,q_t=j,q_{t-1}=i,\\lambda)P(q_t=j|\\{o_k\\}^{t-1}_1,q_{t-1}=i,\\lambda) \\\\ &\\qquad \\times P(\\{o_k\\}^{t-1}_1,q_{t-1}=i|\\lambda) \\\\\n",
    "&= \\sum^N_{i=1}P(\\{o_k\\}^{t-1}_1,q_{t-1}=i|\\lambda)P(q_t=j|q_{t-1}=i,\\lambda)P(o_t|q_t=j,\\lambda) \\\\\n",
    "&= \\sum^N_{i=1}\\alpha_{t-1}(i)a_{ij}b_j(o_t)\n",
    "\\end{align*}\n",
    "$$\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def likelihood(self,Os):\n",
    "    Length = len(Os)\n",
    "    alpha = np.zeros((self.q,Length))\n",
    "    for t,o in enumerate(Os):\n",
    "        for i in range(self.q):\n",
    "            if t==0:\n",
    "                alpha[i,t]=self.pi[i]*self.B[i][self.o2id[o]]\n",
    "            else:\n",
    "                for j in range(self.q):\n",
    "                    alpha[i,t]+=alpha[j,t-1]*self.A[j][i]\n",
    "                alpha[i,t]*=self.B[i][self.o2id[o]]\n",
    "    return sum(alpha[:,-1]),alpha\n",
    "    \n",
    "hmm.computeLikelihood = lambda x:likelihood(hmm,x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.5049999999999999, array([[0.49 ],\n",
      "       [0.015]]))\n",
      "(0.41000000000000003, array([[0.14],\n",
      "       [0.27]]))\n",
      "(0.049999999999999996, array([[0.035],\n",
      "       [0.015]]))\n",
      "(0.034999999999999996, array([[0.035],\n",
      "       [0.   ]]))\n",
      "(0.25599999999999995, array([[0.49  , 0.2485],\n",
      "       [0.015 , 0.0075]]))\n",
      "(0.20599999999999996, array([[0.49 , 0.071],\n",
      "       [0.015, 0.135]]))\n",
      "(0.2246, array([[0.14  , 0.2198],\n",
      "       [0.27  , 0.0048]]))\n",
      "(0.1492, array([[0.14  , 0.0628],\n",
      "       [0.27  , 0.0864]]))\n"
     ]
    }
   ],
   "source": [
    "print(hmm.computeLikelihood([1]))\n",
    "print(hmm.computeLikelihood([0]))\n",
    "print(hmm.computeLikelihood([2]))\n",
    "print(hmm.computeLikelihood([3]))\n",
    "print(hmm.computeLikelihood([1,1]))\n",
    "print(hmm.computeLikelihood([1,0]))\n",
    "print(hmm.computeLikelihood([0,1]))\n",
    "print(hmm.computeLikelihood([0,0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Decoding: Viterbi Algorithm\n",
    "a. Initialization\n",
    "$$\\begin{align*}\n",
    "v_1(j) &= \\pi_jb_j(o_1) &\\qquad 1\\leq j\\leq N \\\\\n",
    "bt_1(j) &= 0 &\\qquad 1\\leq j\\leq N\n",
    "\\end{align*}\n",
    "$$\n",
    "b. Recursion\n",
    "$$\\begin{align*}\n",
    "v_t(j) &=\\max_{\\{q_k\\}_1^{t-1}} P(\\{q_k\\}_1^{t-1},\\{o_k\\}_1^t,q_t=j | \\lambda) \\\\&= \\max^N_{i=1}v_{t-1}(i)a_{ij}b_j(o_t) &\\qquad 1\\leq j\\leq N\\quad ,\\quad 1<t\\leq T\\\\\n",
    "bt_t(j) &= \\arg\\max^N_{i=1}v_{t-1}(i)a_{ij}b_j(o_t) &\\qquad 1\\leq j\\leq N\\quad ,\\quad 1<t\\leq T\\\\\n",
    "\\end{align*}\n",
    "$$\n",
    "c. Termination\n",
    "$$\\begin{align*}\n",
    "P* &= \\max^N_{i=1}v_T(i) \\\\\n",
    "q_T* &= \\arg\\max^N_{i=1}v_T(i)\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode(self,Os):\n",
    "    Length = len(Os)\n",
    "    V = np.zeros((self.q,Length))\n",
    "    bt = [0]*Length\n",
    "    for t,o in enumerate(Os):\n",
    "        for i in range(self.q):\n",
    "            if t==0:\n",
    "                V[i,t]=self.pi[i]*self.B[i][self.o2id[o]]\n",
    "            else:\n",
    "                for j in range(self.q):\n",
    "                    V[i,t]=max(V[i,t],V[j,t-1]*self.A[j][i])\n",
    "                V[i,t]*=self.B[i][self.o2id[o]]\n",
    "        bt[t]=self.id2q[np.argmax(V[:,t])]\n",
    "    P_ = max(V[:,-1])\n",
    "    return P_,bt\n",
    "hmm.decode = lambda x:decode(hmm,x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.27, ['C'])\n",
      "(0.48999999999999994, ['H'])\n",
      "(0.034999999999999996, ['H'])\n",
      "(0.034999999999999996, ['H'])\n"
     ]
    }
   ],
   "source": [
    "for o in hmm.o2id.keys():\n",
    "    print(hmm.decode([o]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0020995200000000006, ['C', 'C', 'C', 'C'])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hmm.decode([0,0,0,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Learning: HMM Training with Forward-Backward Algorithm\n",
    "> Backward Probability\n",
    "\n",
    "a. Initialization\n",
    "$$\\beta_T(i) = 1 \\qquad 1\\leq i\\leq N$$\n",
    "b. Recursion\n",
    "$$\\begin{align*}\n",
    "\\beta_t(i) &= P(\\{o_k\\}_{t+1}^T|q_t=i,\\lambda) \\\\\n",
    "&=\\sum^N_{j=1}a_{ij}b_j(o_{t+1})\\beta_{t+1}(j) \\qquad 1\\leq i\\leq N\\quad,\\quad 1\\leq t<T\n",
    "\\end{align*}\n",
    "$$\n",
    "c. Termination\n",
    "$$P(O|\\lambda)=\\sum^N_{j=1}\\pi_j b_j(o_1)\\beta_1(j)$$\n",
    "<details >\n",
    "<summary><h4>Click to view proof for Backward probability!</h4></summary>\n",
    "$$\\begin{align*}\n",
    "\\beta_t(i) &= P(\\{o_k\\}_{t+1}^T|q_t=i,\\lambda) = \\sum^N_{j=1}P(q_{t+1}=j,o_{t+1},\\{o_k\\}^T_{t+2}|q_t=i,\\lambda) \\\\\n",
    "&= \\sum^N_{j=1}\\frac{P(q_{t+1}=j,o_{t+1},\\{o_k\\}^T_{t+2},q_t=i|\\lambda)}{P(q_t=i|\\lambda)} \\\\\n",
    "&= \\sum^N_{j=1}\\frac{P(o_{t+1}|q_{t+1}=j,\\{o_k\\}^T_{t+2},q_t=i,\\lambda)\\times\\\\P(\\{o_k\\}^T_{t+2}|q_{t+1}=j,q_t=i,\\lambda)\\times\\\\P(q_{t+1}=j|q_t=i,\\lambda)P(q_t=i|\\lambda)}{P(q_t=i|\\lambda)} \\\\\n",
    "&= \\sum^N_{j=1}P(q_{t+1}=j|q_t=i,\\lambda)P(o_{t+1}|q_{t+1}=j,\\lambda)P(\\{o_k\\}^T_{t+2}|q_{t+1}=j,\\lambda) \\\\\n",
    "&= \\sum^N_{j=1}a_{ij}b_j(o_{t+1})\\beta_{t+1}(j)\n",
    "\\end{align*}$$\n",
    "</details>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def likelihood_backwards(self,Os):\n",
    "    Length = len(Os)\n",
    "    beta = np.zeros((self.q,Length))\n",
    "    for t in range(Length-1,-1,-1):\n",
    "        o = Os[t]\n",
    "        for i in range(self.q):\n",
    "            if t==Length-1:\n",
    "                beta[i,t]=1\n",
    "            else:\n",
    "                for j in range(self.q):\n",
    "                    o_tp1 = self.o2id[Os[t+1]]\n",
    "                    tmp=beta[j,t+1]*self.A[i][j]\n",
    "                    tmp*=self.B[j][o_tp1]\n",
    "                    beta[i,t]+=tmp\n",
    "\n",
    "    P = 0\n",
    "    for j in range(self.q):\n",
    "        P+=self.pi[j]*self.B[j][self.o2id[Os[0]]]*beta[j,0]\n",
    "    return P,beta\n",
    "    \n",
    "hmm.likelihood_backwards = lambda x:likelihood_backwards(hmm,x)\n",
    "               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5049999999999999 0.5049999999999999\n",
      "0.41000000000000003 0.41000000000000003\n",
      "0.049999999999999996 0.049999999999999996\n",
      "0.034999999999999996 0.034999999999999996\n",
      "0.25599999999999995 0.2559999999999999\n",
      "0.20599999999999996 0.206\n",
      "0.2246 0.22459999999999997\n",
      "0.1492 0.14920000000000003\n"
     ]
    }
   ],
   "source": [
    "print(hmm.computeLikelihood([1])[0],\n",
    "      hmm.likelihood_backwards([1])[0])\n",
    "print(hmm.computeLikelihood([0])[0],\n",
    "      hmm.likelihood_backwards([0])[0])\n",
    "print(hmm.computeLikelihood([2])[0],\n",
    "      hmm.likelihood_backwards([2])[0])\n",
    "print(hmm.computeLikelihood([3])[0],\n",
    "      hmm.likelihood_backwards([3])[0])\n",
    "print(hmm.computeLikelihood([1,1])[0],\n",
    "      hmm.likelihood_backwards([1,1])[0])\n",
    "print(hmm.computeLikelihood([1,0])[0],\n",
    "      hmm.likelihood_backwards([1,0])[0])\n",
    "print(hmm.computeLikelihood([0,1])[0],\n",
    "      hmm.likelihood_backwards([0,1])[0])\n",
    "print(hmm.computeLikelihood([0,0])[0],\n",
    "      hmm.likelihood_backwards([0,0])[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sampling from HMM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def samples(self,length):\n",
    "    Qs,Os = [],[]\n",
    "    for i in range(length):\n",
    "        if i==0:\n",
    "            q = np.random.choice(self.q,1,\n",
    "                    p=list(self.pi.values()))\n",
    "        else:\n",
    "            q = np.random.choice(self.q,1,\n",
    "                    p=list(self.A[q[0]].values()))\n",
    "        o = np.random.choice(self.o,1,\n",
    "                    p=list(self.B[q[0]].values()))\n",
    "        Qs.append(self.id2q[q[0]])\n",
    "        Os.append(self.id2o[o[0]])\n",
    "    return Qs,Os\n",
    "\n",
    "hmm.samples = lambda x:samples(hmm,x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['H', 'H', 'C', 'C', 'H', 'H'] ['H', 'H', 'C', 'H', 'H', 'H'] 0.008716379111999992 [1, 1, 0, 1, 1, 1] 0.014680071349999992 0.014680071349999988\n",
      "['H', 'H', 'H', 'C', 'H', 'H'] ['H', 'H', 'H', 'H', 'C', 'H'] 0.0006225985079999996 [1, 1, 1, 2, 0, 1] 0.0013778760249999998 0.0013778760249999994\n",
      "['C', 'C', 'H', 'C', 'H', 'C'] ['C', 'C', 'H', 'C', 'H', 'C'] 0.0011110659839999998 [0, 0, 1, 0, 1, 0] 0.007397832399999998 0.0073978324\n",
      "['C', 'H', 'H', 'C', 'H', 'H'] ['C', 'H', 'H', 'C', 'C', 'H'] 0.002016379008 [0, 1, 1, 0, 0, 1] 0.00916802624 0.009168026239999997\n",
      "['H', 'H', 'H', 'H', 'C', 'C'] ['H', 'H', 'H', 'H', 'C', 'C'] 0.0002001209489999999 [1, 1, 3, 1, 0, 0] 0.0006749024749999996 0.000674902475\n",
      "['H', 'C', 'H', 'H', 'H', 'H'] ['H', 'C', 'H', 'C', 'H', 'H'] 0.005489031743999998 [1, 0, 1, 0, 1, 1] 0.012779535999999992 0.012779535999999994\n",
      "['H', 'C', 'H', 'H', 'H', 'H'] ['H', 'C', 'H', 'H', 'H', 'H'] 0.0006225985079999997 [1, 0, 2, 1, 1, 1] 0.0013763984124999997 0.0013763984124999995\n",
      "['C', 'H', 'H', 'H', 'H', 'H'] ['C', 'H', 'H', 'H', 'H', 'H'] 0.0006225985079999997 [0, 1, 1, 1, 3, 1] 0.0010232928624999997 0.0010232928624999995\n",
      "['C', 'H', 'C', 'H', 'C', 'H'] ['C', 'C', 'C', 'H', 'C', 'H'] 0.0009876142080000002 [0, 0, 0, 1, 0, 1] 0.006699543759999999 0.006699543759999999\n",
      "['H', 'H', 'H', 'C', 'H', 'H'] ['H', 'H', 'H', 'C', 'H', 'H'] 0.0006225985079999996 [1, 2, 1, 0, 1, 1] 0.0014985958749999997 0.001498595874999999\n"
     ]
    }
   ],
   "source": [
    "N = 10\n",
    "for i in range(N):\n",
    "    Qs,Os = hmm.samples(6)\n",
    "    l,alpha = hmm.computeLikelihood(Os)\n",
    "    lB,beta = hmm.likelihood_backwards(Os)\n",
    "    lQ,dQs = hmm.decode(Os)\n",
    "    print(Qs,dQs,lQ,Os,l,lB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Transition Probability Matrix $A$\n",
    "\n",
    "$$\\begin{align*}\n",
    "    \\hat{a}_{ij}&=\\frac{\\sum^{T-1}_{t=1}\\xi_t(i,j)}{\\sum^{T-1}_{t=1}\\sum^N_{k=1}\\xi_t(i,k)}\\\\\n",
    "    \\xi_t(i,j) &= \\frac{\\alpha_t(i)a_{ij}b_j(o_{t+1})\\beta_{t+1}(j)}{\\sum^N_{j=1}\\alpha_t(j)\\beta_t(j)}\n",
    "\\end{align*}$$\n",
    "<details >\n",
    "<summary><h4>Click to view proof for transition probability!</h4></summary>\n",
    "\n",
    "</details>\n",
    "\n",
    "> Emission Probabilities $B$\n",
    "\n",
    "$$\\begin{align*}\n",
    "\\hat{b}_j(v_k) &= \\frac{\\sum^T_{t=1 s.t.O_t=v_k}\\gamma_t(j)}{\\sum^T_{t=1}\\gamma_t(j)} \\\\\n",
    "\\gamma_t(j) &= \\frac{\\alpha_t(j)\\beta_t(j)}{\\sum^N_{j=1}\\alpha_t(j)\\beta_t(j)}\n",
    "\\end{align*}$$\n",
    "<details >\n",
    "<summary><h4>Click to view proof for emission probability!</h4></summary>\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def e_step(self,Os):\n",
    "    Length = len(Os)\n",
    "    l,alpha = self.computeLikelihood(Os)\n",
    "    lB,beta = self.likelihood_backwards(Os)\n",
    "    alphabeta = alpha*beta\n",
    "    sum_alphabeta = np.sum(alphabeta,axis=0)\n",
    "    gamma = alphabeta/sum_alphabeta\n",
    "    xi = np.zeros((Length,self.q,self.q))\n",
    "    for t in range(Length-1):\n",
    "        o_tp1 = self.o2id[Os[t+1]]\n",
    "        for i in range(self.q):\n",
    "            for j in range(self.q):\n",
    "                tmp=alpha[i,t]*beta[j,t+1]\n",
    "                tmp*=self.A[i][j]*self.B[j][o_tp1]\n",
    "                xi[t,i,j]=tmp/sum_alphabeta[t]\n",
    "    return l,gamma,xi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def m_step(self,Os,gamma,xi):\n",
    "    atop = np.sum(xi[:-1,:,:],axis=0)\n",
    "    abottom = np.sum(atop,axis=1,keepdims=1)\n",
    "    Os = np.array(Os)\n",
    "    btop = np.zeros((self.o,self.q))\n",
    "    for o in range(self.o):\n",
    "        tmp = gamma[:,Os==self.id2o[o]].sum(axis=1)\n",
    "        btop[o,:] = tmp\n",
    "    bbottom = gamma.sum(axis=1)\n",
    "    return atop,abottom,btop,bbottom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update(self,A,B,pi):\n",
    "    for i in range(self.q):\n",
    "        for j in range(self.q):\n",
    "            self.A[i][j]=A[i,j]\n",
    "        self.pi[i]=pi[i]\n",
    "        for o in range(self.o):\n",
    "            self.B[i][o]=B[o,i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def learn(self,Osamples,iters=10):\n",
    "    ls = []\n",
    "    N = len(Osamples)\n",
    "    for _ in tqdm(range(iters)):\n",
    "        tmp,at,ab,bt,bb,pt = 0,0,0,0,0,0\n",
    "        for Os in Osamples:\n",
    "            l,gamma,xi = self.e_step(Os)\n",
    "            tmp+=np.log(l)\n",
    "            atop,abottom,btop,bbottom = self.m_step(Os,gamma,xi)\n",
    "            at+=atop\n",
    "            ab+=abottom\n",
    "            bt+=btop\n",
    "            bb+=bbottom\n",
    "            pt+=gamma[:,0]\n",
    "        ls.append(tmp)\n",
    "        pi = pt/N\n",
    "        A = at/ab\n",
    "        B = bt/bb\n",
    "        self.update(A,B,pi)\n",
    "    return ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_patch(obj):\n",
    "    obj.computeLikelihood = lambda x:likelihood(obj,x)\n",
    "    obj.decode = lambda x:decode(obj,x)\n",
    "    obj.likelihood_backwards = lambda x:likelihood_backwards(obj,x)\n",
    "    obj.samples = lambda x:samples(obj,x)\n",
    "    obj.e_step = lambda x:e_step(obj,x)\n",
    "    obj.m_step = lambda x,y,z: m_step(obj,x,y,z)  \n",
    "    obj.update = lambda x,y,z: update(obj,x,y,z)\n",
    "    obj.learn = lambda x,y: learn(obj,x,y)\n",
    "    return obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "hmm = add_patch(hmm)\n",
    "N,T = 1000,6\n",
    "Osamples = []\n",
    "for _ in range(N):\n",
    "    Qs,Os = hmm.samples(T)\n",
    "    Osamples.append(Os)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0, 0, 2, 1, 1, 0], [1, 1, 0, 0, 1, 1], [0, 0, 0, 2, 2, 1]]\n"
     ]
    }
   ],
   "source": [
    "print(Osamples[0:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = HMM()\n",
    "model.setDistinctHiddensAndObservations([0,1,2,3],[\"H\",\"C\"])\n",
    "model = add_patch(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<class 'dict'>, {0: {0: 0.1695625654979474, 1: 0.8304374345020527}, 1: {0: 0.392994367262893, 1: 0.6070056327371071}})\n",
      "defaultdict(<class 'dict'>, {0: {0: 0.5051550364682366, 1: 0.16639562314178313, 2: 0.03364718966748458, 3: 0.29480215072249555}, 1: {0: 0.11421778010227736, 1: 0.2700486184649047, 2: 0.39341290226705977, 3: 0.22232069916575817}})\n",
      "{0: 0.7322150776422564, 1: 0.26778492235774365}\n"
     ]
    }
   ],
   "source": [
    "print(model.A)\n",
    "print(model.B)\n",
    "print(model.pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 11.11it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f8b3845b650>]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "iters = 10\n",
    "ls = model.learn(Osamples,iters)\n",
    "plt.plot(range(iters),ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<class 'dict'>, {0: {0: 0.24602967920192576, 1: 0.7539703207980725}, 1: {0: 0.4996312146331193, 1: 0.5003687853668808}})\n",
      "defaultdict(<class 'dict'>, {0: {0: 0.5946764066844089, 1: 0.35196306520703613, 2: 0.01489604598237435, 3: 0.0384644821261796}, 1: {0: 0.23493489418596958, 1: 0.650708396153463, 2: 0.07356037327387575, 3: 0.04079633638669227}})\n",
      "{0: 0.5056613082894451, 1: 0.49433869171055517}\n"
     ]
    }
   ],
   "source": [
    "print(model.A)\n",
    "print(model.B)\n",
    "print(model.pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<class 'dict'>, {0: {0: 0.7, 1: 0.3}, 1: {0: 0.8, 1: 0.2}})\n",
      "defaultdict(<class 'dict'>, {0: {0: 0.2, 1: 0.7, 2: 0.05, 3: 0.05}, 1: {0: 0.9, 1: 0.05, 2: 0.05, 3: 0}})\n",
      "{0: 0.7, 1: 0.3}\n"
     ]
    }
   ],
   "source": [
    "print(hmm.A)\n",
    "print(hmm.B)\n",
    "print(hmm.pi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References\n",
    "- https://web.stanford.edu/~jurafsky/slp3/A.pdf\n",
    "- https://en.wikipedia.org/wiki/Baum%E2%80%93Welch_algorithm\n",
    "- http://personal.ee.surrey.ac.uk/Personal/P.Jackson/tutorial/hmm_tut4.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
