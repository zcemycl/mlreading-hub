{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "\n",
    "class HMM:\n",
    "    def __init__(self):\n",
    "        self.params = defaultdict(dict)\n",
    "        self.o2id,self.id2o = dict(),dict()\n",
    "        self.q2id,self.id2q = dict(),dict()\n",
    "        self.ct,self.ce = dict(),dict()\n",
    "    def _setDistinctObservations(self,distO):\n",
    "        self.o = len(distO)\n",
    "        for i,o in enumerate(distO):\n",
    "            self.o2id[o]=i\n",
    "            self.id2o[i]=o\n",
    "    def _setDistinctHiddens(self,distQ):\n",
    "        self.q = len(distQ)\n",
    "        A = np.random.uniform(0,1,(self.q,self.q))\n",
    "        A /= np.sum(A,axis=1,keepdims=1)\n",
    "        B = np.random.uniform(0,1,(self.q,self.o))\n",
    "        B /= np.sum(B,axis=1,keepdims=1)\n",
    "        pi = np.random.uniform(0,1,self.q)\n",
    "        pi/= np.sum(pi)\n",
    "        self.A = defaultdict(dict)\n",
    "        self.B = defaultdict(dict)\n",
    "        self.pi = {}\n",
    "        for i,q in enumerate(distQ):\n",
    "            self.q2id[q]=i\n",
    "            self.id2q[i]=q\n",
    "            for j,q_ in enumerate(distQ):\n",
    "                self.A[i][j] = A[i][j]\n",
    "            for k in range(self.o):\n",
    "                self.B[i][k] = B[i][k]\n",
    "            self.pi[i] = pi[i]\n",
    "    def setDistinctHiddensAndObservations(self,distO,distQ):\n",
    "        self._setDistinctObservations(distO)\n",
    "        self._setDistinctHiddens(distQ)\n",
    "    def setSpecificEmit(self,qSym,emitDict):\n",
    "        assert sum(emitDict.values())==1, \"Sum of probability is not 1\"\n",
    "        for i in self.B[self.q2id[qSym]].keys():\n",
    "            # assert in dict\n",
    "            self.B[self.q2id[qSym]][i]=emitDict.get(self.id2o[i],0)\n",
    "        assert sum(self.B[self.q2id[qSym]].values())==1, \"Sum of probability is not 1\"\n",
    "    def setSpecificTransit(self,qSym,tranDict):\n",
    "        assert sum(tranDict.values())==1, \"Sum of probability is not 1\"\n",
    "        for i in self.A[self.q2id[qSym]].keys():\n",
    "            self.A[self.q2id[qSym]][i]=tranDict.get(self.id2q[i],0)\n",
    "        assert sum(self.A[self.q2id[qSym]].values())==1, \"Sum of probability is not 1\"\n",
    "    def setInitial(self,initDict):\n",
    "        assert sum(initDict.values())==1, \"Sum of probability is not 1\"\n",
    "        for i in self.pi.keys():\n",
    "            # assert in dict\n",
    "            self.pi[i]=initDict.get(self.id2q[i],0)\n",
    "        assert sum(self.pi.values())==1, \"Sum of probability is not 1\"\n",
    "    def computeLikelihood(self,Os):\n",
    "        raise NotImplementedError(\"You need to implement function1 when you inherit from Model\")\n",
    "    def decode(self,Os):\n",
    "        raise NotImplementedError(\"You need to implement function1 when you inherit from Model\")\n",
    "    def learn(self,Qs,Os):\n",
    "        raise NotImplementedError(\"You need to implement function1 when you inherit from Model\")\n",
    "        \n",
    "def likelihood(self,Os):\n",
    "    Length = len(Os)\n",
    "    alpha = np.zeros((self.q,Length))\n",
    "    for t,o in enumerate(Os):\n",
    "        for i in range(self.q):\n",
    "            if t==0:\n",
    "                alpha[i,t]=self.pi[i]*self.B[i][self.o2id[o]]\n",
    "            else:\n",
    "                for j in range(self.q):\n",
    "                    alpha[i,t]+=alpha[j,t-1]*self.A[j][i]\n",
    "                alpha[i,t]*=self.B[i][self.o2id[o]]\n",
    "    return sum(alpha[:,-1]),alpha\n",
    "def decode(self,Os):\n",
    "    Length = len(Os)\n",
    "    V = np.zeros((self.q,Length))\n",
    "    bt = [0]*Length\n",
    "    for t,o in enumerate(Os):\n",
    "        for i in range(self.q):\n",
    "            if t==0:\n",
    "                V[i,t]=self.pi[i]*self.B[i][self.o2id[o]]\n",
    "            else:\n",
    "                for j in range(self.q):\n",
    "                    V[i,t]=max(V[i,t],V[j,t-1]*self.A[j][i])\n",
    "                V[i,t]*=self.B[i][self.o2id[o]]\n",
    "        bt[t]=self.id2q[np.argmax(V[:,t])]\n",
    "    P_ = max(V[:,-1])\n",
    "    return P_,bt\n",
    "def samples(self,length):\n",
    "    Qs,Os = [],[]\n",
    "    for i in range(length):\n",
    "        if i==0:\n",
    "            q = np.random.choice(self.q,1,\n",
    "                    p=list(self.pi.values()))\n",
    "        else:\n",
    "            q = np.random.choice(self.q,1,\n",
    "                    p=list(self.A[q[0]].values()))\n",
    "        o = np.random.choice(self.o,1,\n",
    "                    p=list(self.B[q[0]].values()))\n",
    "        Qs.append(self.id2q[q[0]])\n",
    "        Os.append(self.id2o[o[0]])\n",
    "    return Qs,Os\n",
    "def learn(self,Qs,Os):\n",
    "    Length = len(Qs)\n",
    "    if Length==0: return \n",
    "    for i,(q,o) in enumerate(zip(Qs,Os)):\n",
    "        q_ = self.q2id[q]\n",
    "        o_ = self.o2id[o]\n",
    "        if i==0:\n",
    "            self.ct[None]=self.ct.get(None,0)+1\n",
    "            self.ct[(None,q_)]=self.ct.get((None,q_),0)+1\n",
    "        if i!=Length-1:\n",
    "            q_1 = self.q2id[Qs[i+1]]\n",
    "            self.ct[q_]=self.ct.get(q_,0)+1\n",
    "            self.ct[(q_,q_1)]=self.ct.get((q_,q_1),0)+1\n",
    "        self.ce[q_]=self.ce.get(q_,0)+1\n",
    "        self.ce[(q_,o_)]=self.ce.get((q_,o_),0)+1\n",
    "    for i in range(self.q):\n",
    "        self.pi[i]=self.ct.get((None,i),0)/self.ct.get(None,0)\n",
    "        for j in range(self.q):\n",
    "            self.A[i][j]=(self.ct.get((i,j),0)+1)/(self.ct.get(i,0)+self.q)\n",
    "        for o in range(self.o):\n",
    "            self.B[i][o]=(self.ce.get((i,o),0)+1)/(self.ce.get(i,0)+self.o)\n",
    "\n",
    "def add_patch(obj):\n",
    "    obj.computeLikelihood = lambda x:likelihood(obj,x)\n",
    "    obj.decode = lambda x:decode(obj,x)\n",
    "    obj.samples = lambda x: samples(obj,x)\n",
    "    obj.learn = lambda x,y: learn(obj,x,y)\n",
    "    return obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadData(PATH):\n",
    "    words,tags = [],[]\n",
    "    vocab,vocabtag = set(),set()\n",
    "    with open(PATH) as f:\n",
    "        lines = f.readlines()\n",
    "        sent,senttag = [],[]\n",
    "        for line in lines:\n",
    "            line = line.strip()\n",
    "            tokens = line.split(\" \")\n",
    "            if len(tokens)>1:\n",
    "                sent.append(tokens[0])\n",
    "                senttag.append(tokens[1])\n",
    "                vocab.add(tokens[0])\n",
    "                vocabtag.add(tokens[1])\n",
    "            else:\n",
    "                words.append(sent)\n",
    "                tags.append(senttag)\n",
    "                sent,senttag=[],[]        \n",
    "    return words,tags,vocab,vocabtag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part of Speech Tagging\n",
    "- https://www.clips.uantwerpen.be/conll2000/chunking/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDataPATH = \"/home/yui/Documents/data/nlp/pos/train.txt\"\n",
    "words,tags,vocab,vocabtag = loadData(trainDataPATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "testDataPATH = \"/home/yui/Documents/data/nlp/pos/test.txt\"\n",
    "words_,tags_,_,_ = loadData(testDataPATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of vocabularies:  19122\n",
      "Number of tags:  44\n",
      "Number of sentences for training:  8936 8936\n",
      "Number of sentences for testing:  2012 2012\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of vocabularies: \",len(vocab))\n",
    "print(\"Number of tags: \",len(vocabtag))\n",
    "print(\"Number of sentences for training: \",len(words),len(tags))\n",
    "print(\"Number of sentences for testing: \",len(words_),len(tags_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8936/8936 [27:13<00:00,  5.47it/s]\n"
     ]
    }
   ],
   "source": [
    "model = HMM()\n",
    "model.setDistinctHiddensAndObservations(list(vocab),\n",
    "            list(vocabtag))\n",
    "model = add_patch(model)\n",
    "for i in tqdm(range(len(words))):\n",
    "    model.learn(tags[i],words[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Metrics\n",
    "1. Accuracy $\\frac{TP+TN}{TP+TN+FP+FN}$\n",
    "2. Precision $\\frac{TP}{TP+FP}$\n",
    "3. Recall $\\frac{TP}{TP+FN}$\n",
    "4. F1 score $2\\frac{P\\times R}{P+R}$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evalPerformance(model,words,tags,name=\"Train\"):\n",
    "    TP,total = 0,0\n",
    "    for i in tqdm(range(len(words))):\n",
    "        try:\n",
    "            _,res = model.decode(words[i])\n",
    "            for j in range(len(res)):\n",
    "                TP += res[j]==tags[i][j]\n",
    "                total+=1\n",
    "        except:\n",
    "            pass\n",
    "    print(\"{} Accuracy: \".format(name),TP/total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8936/8936 [03:25<00:00, 43.41it/s]\n",
      "  1%|          | 24/2012 [00:00<00:21, 93.27it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy:  0.9231415927113689\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2012/2012 [00:19<00:00, 101.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy:  0.9368231046931408\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "evalPerformance(model,words,tags,name=\"Train\")\n",
    "evalPerformance(model,words_,tags_,name=\"Test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
